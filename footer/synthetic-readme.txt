These synthetic benchmarks represent the types of workloads seen in machine learning workloads.
Specifically, many columns of (nearly random) numeric data where dictionary and compression tools don't help much.
These come from the parquet benchmarking project: https://github.com/Neelaksh-Singh/gresearch_parquet_benchmarking
which gives more context and details.

Specifically, these were generated via https://github.com/Neelaksh-Singh/gresearch_parquet_benchmarking/blob/main/src/test_data_generator.cc

A copy of this file has been added as sythetic-test_data_generator.cc

